{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"enroll.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"-Nrt9nn2lZyO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":368},"outputId":"c2fd2ac9-293e-4251-8e68-7aadae82d76c","executionInfo":{"status":"error","timestamp":1590473327090,"user_tz":-540,"elapsed":1016,"user":{"displayName":"Sujin Lee","photoUrl":"","userId":"12954063167699440993"}}},"source":["import torch\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","import numpy as np\n","import pandas as pd\n","import math\n","import os\n","import configure as c\n","from DB_wav_reader import read_feats_structure\n","from SR_Dataset import read_MFB, ToTensorTestInput\n","from model.model import background_resnet\n","import matplotlib.pyplot as plt\n","\n","def load_model(use_cuda, log_dir, cp_num, embedding_size, n_classes):\n","    model = background_resnet(embedding_size=embedding_size, num_classes=n_classes)\n","    if use_cuda:\n","        model.cuda()\n","    print('=> loading checkpoint')\n","    # original saved file with DataParallel\n","    checkpoint = torch.load(log_dir + '/checkpoint_' + str(cp_num) + '.pth')\n","    # create new OrderedDict that does not contain `module.`\n","    model.load_state_dict(checkpoint['state_dict'])\n","    model.eval()\n","    return model\n","\n","def split_enroll_and_test(dataroot_dir):\n","    DB_all = read_feats_structure(dataroot_dir)\n","    enroll_DB = pd.DataFrame()\n","    test_DB = pd.DataFrame()\n","    \n","    enroll_DB = DB_all[DB_all['filename'].str.contains('enroll.p')]\n","    test_DB = DB_all[DB_all['filename'].str.contains('test.p')]\n","    \n","    # Reset the index\n","    enroll_DB = enroll_DB.reset_index(drop=True)\n","    test_DB = test_DB.reset_index(drop=True)\n","    return enroll_DB, test_DB\n","\n","def get_embeddings(use_cuda, filename, model, test_frames):\n","    total = []\n","    input, label = read_MFB(filename) # input size:(n_frames, n_dims)\n","\n","    print(\"len(input) : \", len(input))\n","    \n","    tot_segments = math.ceil(len(input)/test_frames)# total number of segments with 'test_frames' \n","    print(\"tot_segments : \", tot_segments)\n","    \n","    activation = 0\n","    with torch.no_grad():\n","        for i in range(tot_segments):\n","            temp_input = input[i*test_frames:i*test_frames+test_frames]\n","            \n","            TT = ToTensorTestInput()\n","            temp_input = TT(temp_input) # size:(1, 1, n_dims, n_frames)\n","    \n","            if use_cuda:\n","                temp_input = temp_input.cuda()\n","            temp_activation,_ = model(temp_input)\n","            total.append(list(np.array(temp_activation)[0]))\n","            activation += torch.sum(temp_activation, dim=0, keepdim=True)\n","    \n","    activation = l2_norm(activation, 1)\n","                \n","    return total\n","\n","def l2_norm(input, alpha):\n","    input_size = input.size()  # size:(n_frames, dim)\n","    buffer = torch.pow(input, 2)  # 2 denotes a squared operation. size:(n_frames, dim)\n","    normp = torch.sum(buffer, 1).add_(1e-10)  # size:(n_frames)\n","    norm = torch.sqrt(normp)  # size:(n_frames)\n","    _output = torch.div(input, norm.view(-1, 1).expand_as(input))\n","    output = _output.view(input_size)\n","    # Multiply by alpha = 10 as suggested in https://arxiv.org/pdf/1703.09507.pdf\n","    output = output * alpha\n","    return output\n","\n","def enroll_per_spk(use_cuda, test_frames, model, DB, embedding_dir):\n","    \"\"\"\n","    Output the averaged d-vector for each speaker (enrollment)\n","    Return the dictionary (length of n_spk)\n","    \"\"\"\n","    n_files = len(DB) # 10\n","    enroll_speaker_list = sorted(set(DB['speaker_id']))\n","    \n","    embeddings = {}\n","    \n","    # Aggregates all the activations\n","    print(\"Start to aggregate all the d-vectors per enroll speaker\")\n","    \n","    for i in range(n_files):\n","        filename = DB['filename'][i]\n","        spk = DB['speaker_id'][i]\n","        \n","        activation = get_embeddings(use_cuda, filename, model, test_frames)\n","        if spk in embeddings:\n","            embeddings[spk] += activation\n","        else:\n","            embeddings[spk] = activation\n","            \n","        print(\"Aggregates the activation (spk : %s)\" % (spk))\n","        \n","    if not os.path.exists(embedding_dir):\n","        os.makedirs(embedding_dir)\n","        \n","    # Save the embeddings\n","    for spk_index in enroll_speaker_list:\n","        embedding_path = os.path.join(embedding_dir, spk_index+'.pth')\n","        torch.save(embeddings[spk_index], embedding_path)\n","        print(\"Save the embeddings for %s\" % (spk_index))\n","    return embeddings\n","    \n","def main():\n","        \n","    # Settings\n","    use_cuda = False\n","    log_dir = 'model_saved'\n","    embedding_size = 128\n","    cp_num = 24 # Which checkpoint to use?\n","    n_classes = 251\n","    test_frames = 200\n","    \n","    # Load model from checkpoint\n","    model = load_model(use_cuda, log_dir, cp_num, embedding_size, n_classes)\n","    \n","    # Get the dataframe for enroll DB\n","    enroll_DB, test_DB = split_enroll_and_test('filterbank/test')\n","    \n","    # Where to save embeddings\n","    embedding_dir = 'enroll_embeddings'\n","    \n","    # Perform the enrollment and save the results\n","    enroll_per_spk(use_cuda, test_frames, model, enroll_DB, embedding_dir)\n","    \n","    \"\"\" Test speaker list\n","    '103F3021', '207F2088', '213F5100', '217F3038', '225M4062', \n","    '229M2031', '230M4087', '233F4013', '236M3043', '240M3063'\n","    \"\"\" \n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":5,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-592745a1e460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mconfigure\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mDB_wav_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_feats_structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mSR_Dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_MFB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToTensorTestInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'configure'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"f6A03OLUmGAx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"13e7ba2f-133b-480a-db19-129286dc49bb","executionInfo":{"status":"ok","timestamp":1590473309503,"user_tz":-540,"elapsed":22200,"user":{"displayName":"Sujin Lee","photoUrl":"","userId":"12954063167699440993"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2UDusJ8rlZyW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":351},"outputId":"f6665ed5-fa9f-4968-972f-f668dd151fdc","executionInfo":{"status":"error","timestamp":1590473245293,"user_tz":-540,"elapsed":1917,"user":{"displayName":"Sujin Lee","photoUrl":"","userId":"12954063167699440993"}}},"source":["from sklearn.cluster import KMeans\n","from pydub import AudioSegment"],"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-4ea7ed222b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q matplotlib-venn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydub'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"5VZrwfs2lZyb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":130},"outputId":"9e41f6d4-f1ab-404e-9292-078aa50f3742","executionInfo":{"status":"error","timestamp":1590473166873,"user_tz":-540,"elapsed":1227,"user":{"displayName":"Sujin Lee","photoUrl":"","userId":"12954063167699440993"}}},"source":["def extract_section(file_path, wav_file_path):\n","    # Settings\n","    use_cuda = False\n","    log_dir = 'model_saved'\n","    embedding_size = 128\n","    cp_num = 24 # Which checkpoint to use?\n","    n_classes = 251\n","    test_frames = 100 #1초당 feature\n","\n","    model = load_model(use_cuda, log_dir, cp_num, embedding_size, n_classes)\n","    test_embedding2 = get_embeddings(use_cuda, file_path, model, test_frames)\n","\n","    X = test_embedding2\n","    kmeans = KMeans(n_clusters=3)\n","    kmeans.fit(X)\n","    y_kmeans = kmeans.predict(X)\n","    print(y_kmeans)\n","    \n","    '''plt.scatter(np.array(X)[:, 0], np.array(X)[:, 1], c=y_kmeans, s=50, cmap='viridis')\n","    centers = kmeans.cluster_centers_\n","    plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)'''\n","    \n","    section = [0]\n","    cnt = 0\n","    for i in range(0, len(y_kmeans)-1):\n","        if (y_kmeans[i] != y_kmeans[i+1]) && cnt>1:\n","            section.append((i+1)*1000)\n","        else:\n","          cnt++\n","            \n","    #export sound\n","    sound = AudioSegment.from_wav(wav_file_path)\n","    \n","    for i in range(1, len(section)):\n","        sound_cut = sound[section[i-1]:section[i]]\n","        print(section[i-1], section[i])\n","        sound_cut.export(\"output/voice\"+str(i-1)+\".wav\", format=\"wav\")\n","\n","    sound_cut = sound[section[len(section)-1]:]\n","    sound_cut.export(\"output/voice\"+str(len(section)-1)+\".wav\", format=\"wav\")"],"execution_count":1,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-8b6daadfbaff>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    if (y_kmeans[i] != y_kmeans[i+1]) && cnt>1:\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"6KUHSYUdlZyf","colab_type":"code","colab":{},"outputId":"7933ac82-edf1-4ee3-fe85-195cb8a67a42"},"source":["extract_section('test_data_pickle/rand_overlay136-rm_silence.p', 'rand_overlay_136-rm_silence.wav')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["=> loading checkpoint\n","len(input) :  1484\n","tot_segments :  15\n","[2 2 2 2 2 2 0 0 0 1 1 1 1 1 1]\n","0 6000\n","6000 9000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ShDhOPezlZym","colab_type":"code","colab":{},"outputId":"a8327565-f7d3-4fb8-b9b5-37fcdfc3551b"},"source":["sec = extract_section('test_data_pickle/rand_overlay136-rm_silence.p', 'rand_overlay_136-rm_silence.wav')\n","sound = AudioSegment.from_wav('rand_overlay_136-rm_silence.wav')\n","\n","for i in range(1, len(sec)):\n","    sound_cut = sound[sec[i-1]:sec[i]]\n","    print(sec[i-1], sec[i])\n","    sound_cut.export(\"output/voice\"+str(i-1)+\".wav\", format=\"wav\")\n","\n","sound_cut = sound[sec[len(sec)-1]:]\n","sound_cut.export(\"output/voice\"+str(len(sec)-1)+\".wav\", format=\"wav\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 6000\n","6000 9000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<_io.BufferedRandom name='output/voice2.wav'>"]},"metadata":{"tags":[]},"execution_count":49}]}]}